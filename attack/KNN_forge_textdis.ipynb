{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dd\n",
      "uncompatible keys: <All keys matched successfully>\n",
      "model:emperical-forged_bit_acc:(1.0, 0.0) acc:(1.0, 0.0)\n",
      "dd\n",
      "uncompatible keys: <All keys matched successfully>\n",
      "model:emperical-forged_bit_acc:(1.0, 0.0) acc:(1.0, 0.0)\n",
      "dd\n",
      "uncompatible keys: <All keys matched successfully>\n",
      "model:emperical-forged_bit_acc:(1.0, 0.0) acc:(1.0, 0.0)\n",
      "dd\n",
      "uncompatible keys: <All keys matched successfully>\n",
      "model:emperical-forged_bit_acc:(0.9238199949264526, 0.00018011396433706748) acc:(1.0, 0.0)\n",
      "dd\n",
      "uncompatible keys: <All keys matched successfully>\n",
      "model:emperical-forged_bit_acc:(0.9902400255203248, 5.503843033238809e-07) acc:(1.0, 0.0)\n",
      "dd\n",
      "uncompatible keys: <All keys matched successfully>\n",
      "model:emperical-forged_bit_acc:(0.9897799730300904, 1.8962239579423112e-07) acc:(1.0, 0.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/mnt/shared/Huggingface/sharedcode/Stegastamp_CR\")\n",
    "sys.path.append(\"/data/shared/Huggingface/sharedcode/Stegastamp_CR\")\n",
    "from utils.helpers import *\n",
    "from dataset import CustomImageFolder\n",
    "from torchvision import transforms\n",
    "from functools import partial\n",
    "import torch\n",
    "from functions import *\n",
    "from clustering_function import text_low,text_mid,text_high\n",
    "from torchvision.datasets import ImageFolder\n",
    "from clustering_function import cluster\n",
    "from sklearn.manifold import TSNE\n",
    "import csv\n",
    "\n",
    "\n",
    "mi = \"\" #mi\n",
    "# forge setting \n",
    "text_num = 4          # 1 4\n",
    "random = False\n",
    "transform_pipe = [\n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.ToTensor(),\n",
    "]\n",
    "normalize_ = transforms.Normalize(mean=[0.5,0.5,0.5],std=[0.5,0.5,0.5])\n",
    "un_normalize_ = transforms.Normalize([-1,-1,-1],[2,2,2])\n",
    "\n",
    "set_seeds(2024)\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "for model_choice in [\"stega\"]:\n",
    "    for data_choice in [\"CelebA\",\"COCO\"]:\n",
    "        data_dir = {\"COCO\":\"/data/shared/coco2017/test2017\",\"CelebA\":\"/data/shared/deepfake/CelebA-HQ/val\"}\n",
    "        ckp_dir = f\"/data/shared/Huggingface/sharedcode/Stegastamp_Train/{mi}weights/{data_choice}/{model_choice}\"\n",
    "\n",
    "        if model_choice == 'hidden':\n",
    "            transform_pipe.append(transforms.Normalize(mean=[0.5,0.5,0.5],std=[0.5,0.5,0.5]))\n",
    "        transform = transforms.Compose(transform_pipe)\n",
    "        if data_choice == \"CelebA\":\n",
    "            ds = ImageFolder(data_dir[data_choice],transform=transform)\n",
    "        else:\n",
    "            ds = CustomImageFolder(data_dir[data_choice],transform,num=1000)\n",
    "        message_len = 100 if model_choice == \"hidden\" else 100\n",
    "\n",
    "        # functions\n",
    "        get_wmimages = partial(get_wmimages,ds=ds,device=device,model_choice=model_choice)\n",
    "        get_images = partial(get_images,ds=ds,device=device)\n",
    "        extract_message = partial(extract_message,device=device,model_choice=model_choice)\n",
    "\n",
    "        # tsne forge setting\n",
    "        tolerant = cal_tolerant(message_len)\n",
    "        batch_size = 16\n",
    "        alpha = 1\n",
    "        if text_num == 1:\n",
    "            attack_num = 1       # 1 30\n",
    "        else:\n",
    "            attack_num = 30\n",
    "        sample_num = 5\n",
    "        use_vae = False\n",
    "\n",
    "        ckp_list = [\"emperical\"]\n",
    "        # ckp_list = sorted(os.listdir(ckp_dir))\n",
    "        \n",
    "        if f\"{mi}OO\" in ckp_list:\n",
    "            ckp_list.remove(f\"{mi}OO\")\n",
    "            ckp_list.insert(0,f\"{mi}OO\")\n",
    "\n",
    "        \n",
    "        for gpname,text_strings in zip([\"low\",\"mid\",\"high\"],[text_low,text_mid,text_high]):\n",
    "            csv_file = f\"../forged_results/text_distance/{data_choice}_{model_choice}_{gpname}_{text_num}_{mi}_alpha{alpha}.csv\"\n",
    "            text_list = [generate_message(message_len,t,1) for t in text_strings]\n",
    "            for op in ckp_list:\n",
    "                if op == \"OO\":\n",
    "                    ckp_path = os.path.join(ckp_dir,op,'epoch_499_state100.pth')\n",
    "                elif op == \"emperical\":\n",
    "                    ckp_path = os.path.join(ckp_dir,op,'epoch_499_state.pth')\n",
    "                else:\n",
    "                    ckp_path = os.path.join(ckp_dir,op,'epoch_99_state.pth')\n",
    "                encoder,decoder = load_weights(ckp_path,model_choice,message_len)\n",
    "                encoder.eval(),decoder.eval()\n",
    "                # get a watermarked image as target \n",
    "                target_image,target_residual = get_wmimages(text=text_list[-1],image_i=[666],encoder=encoder)\n",
    "                # watermarked images by different text\n",
    "                bit_acc_list = []\n",
    "                acc_list = []\n",
    "                for j in range(0,text_num*sample_num,text_num):\n",
    "                    wm_images,residual_predictions = zip(*[get_wmimages(text=t,image_i=range((i+j)*attack_num,(i+j+1)*attack_num),encoder=encoder) for i,t in enumerate(text_list)])\n",
    "                    if use_vae:\n",
    "                        residual_predictions = [get_residual_prediction(wm_images_i,batch_size,device,method=\"diffusion\") for wm_images_i in wm_images]\n",
    "                    wm_images = list(wm_images)\n",
    "                    residual_predictions = list(residual_predictions)\n",
    "                    residual_predictions.append(target_residual)\n",
    "                    # TSNE\n",
    "                    if text_num != 1:\n",
    "                        data = torch.cat(residual_predictions,dim=0).detach().cpu()\n",
    "                        flattened_data = data.view((text_num)*attack_num+1,-1).numpy()\n",
    "                        tsne = TSNE(n_components=2, random_state=10000)\n",
    "                        reduced_data = tsne.fit_transform(flattened_data)\n",
    "\n",
    "                        # cluster\n",
    "                        cluster_labels,cluster_centers = cluster(reduced_data,text_num,\"km\")\n",
    "                        # print(cluster_labels.shape,cluster_centers.shape)\n",
    "                        target_label = cluster_labels[-1]\n",
    "                        attack_samples = data[cluster_labels == target_label]\n",
    "\n",
    "                        # rescale\n",
    "                        attack_samples = un_normalize_(attack_samples)  # 0-1\n",
    "                        attack_sample = attack_samples.mean(axis=0)\n",
    "                        attack_sample = normalize_(attack_sample) # -1,1\n",
    "                        attack_pattern = attack_sample.unsqueeze(0).to(device)\n",
    "                    \n",
    "                    # print(attack_samples.shape)\n",
    "                    else:\n",
    "                        attack_sample = residual_predictions[-1]\n",
    "                        attack_pattern = attack_sample.to(device)\n",
    "\n",
    "                    # forge\n",
    "                    original_images = get_images(image_i=range(900,1000)).to(device)\n",
    "                    # original_images = to0255(original_images)\n",
    "                    # attack_pattern = to0255(attack_pattern)\n",
    "\n",
    "                    forged_image = (original_images + alpha * attack_pattern)\n",
    "                    # print(f\"attack_pattern:{attack_pattern}\")\n",
    "                    # print(f\"original_images:{original_images}\")\n",
    "                    forged_image = torch.clamp(forged_image, min=-1, max=1)\n",
    "\n",
    "                    forged_prediction,_ = extract_message(image_tensor=forged_image,decoder=decoder,model_choice=model_choice)\n",
    "                    gt_text = text_list[-1].repeat(forged_prediction.size(0),1).to(device)\n",
    "                    difference = (forged_prediction != gt_text).float()\n",
    "                    correct = (difference.sum(dim=1)<=tolerant).float()\n",
    "                    acc = correct.mean(dim=0).item()\n",
    "                    bitwise_accuracy = (1.0 - difference.mean(dim=1))\n",
    "                    bitwise_accuracy = torch.mean(bitwise_accuracy)\n",
    "                    bit_acc_list.append(bitwise_accuracy.item())\n",
    "                    acc_list.append(acc)\n",
    "                u_bit_acc,std_bit_acc = calculate_mean_and_variance(bit_acc_list)\n",
    "                u_acc,std_acc = calculate_mean_and_variance(acc_list)\n",
    "                print(f\"model:{op}-forged_bit_acc:{u_bit_acc,std_bit_acc} acc:{u_acc,std_acc}\")\n",
    "                csv_dict = {\"model\":op,\"u_bit_acc\":u_bit_acc,\"std_bit_acc\":std_bit_acc,\"u_acc\":u_acc,\"std_acc\":std_acc}\n",
    "                with open(csv_file, mode='a', newline='') as file:\n",
    "                    fieldnames = csv_dict.keys()\n",
    "                    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "                    if file.tell() == 0:\n",
    "                        writer.writeheader()\n",
    "                    writer.writerow(csv_dict)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
