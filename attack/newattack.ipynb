{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 35.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "op: miGN_0.1\n",
      "temp: 1111110010011111110011000010100011000011001100001111111101100100101110011001000011100000010010000000\n",
      "target: 0101011100001111011010100001101011010011001110001110111001100011101100011011010111011000011110000011\n",
      "hamming distance with temp with target_message: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 48.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "op: miGN_0.1\n",
      "temp: 1111110010011101110011100010110011000000001000101010111001000000001100011001000011001000011010000001\n",
      "target: 0101011100001111011010100001101011010011001110001110111001100011101100011011010111011000011110000011\n",
      "hamming distance with temp with target_message: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 47.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "op: miGN_0.1\n",
      "temp: 1111110011011100110011100010100011000000001000101111111101000000101100010010000111001011010000000000\n",
      "target: 0101011100001111011010100001101011010011001110001110111001100011101100011011010111011000011110000011\n",
      "hamming distance with temp with target_message: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 38.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "op: miGN_0.1\n",
      "temp: 1111000010001111110010100000100011000000010000001111110101000100101100110000000011000010010000000000\n",
      "target: 0101011100001111011010100001101011010011001110001110111001100011101100011011010111011000011110000011\n",
      "hamming distance with temp with target_message: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 38.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "op: miGN_0.1\n",
      "temp: 1111110011011101110011100010100011000001101000101111011101000000001100011001001011000000010010000001\n",
      "target: 0101011100001111011010100001101011010011001110001110111001100011101100011011010111011000011110000011\n",
      "hamming distance with temp with target_message: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 35.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "op: miGN_0.1\n",
      "temp: 1101100011011001110010100010110011000000001000101110111001000000001100011010000011011011010010000000\n",
      "target: 0101011100001111011010100001101011010011001110001110111001100011101100011011010111011000011110000011\n",
      "hamming distance with temp with target_message: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 36.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "op: miGN_0.1\n",
      "temp: 1111100010011101110011100010111010000000001000101010111001000000101100010010000011001011011010000000\n",
      "target: 0101011100001111011010100001101011010011001110001110111001100011101100011011010111011000011110000011\n",
      "hamming distance with temp with target_message: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 38.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "op: miGN_0.1\n",
      "temp: 1111000011011110110011100010110011000011001000101111011101000000000100011000000111001011010100000000\n",
      "target: 0101011100001111011010100001101011010011001110001110111001100011101100011011010111011000011110000011\n",
      "hamming distance with temp with target_message: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 36.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "op: miGN_0.1\n",
      "temp: 1111000110011111110010000000100011000011001000001111111101100001101101111000001001001000011000000000\n",
      "target: 0101011100001111011010100001101011010011001110001110111001100011101100011011010111011000011110000011\n",
      "hamming distance with temp with target_message: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 37.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "op: miGN_0.1\n",
      "temp: 1111000110001101010010000000100011100011101000100111011001100100100101011001000001011000010000000000\n",
      "target: 0101011100001111011010100001101011010011001110001110111001100011101100011011010111011000011110000011\n",
      "hamming distance with temp with target_message: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [00:00<00:02, 32.00it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 76\u001b[0m\n\u001b[1;32m     74\u001b[0m temp1_tensor \u001b[38;5;241m=\u001b[39m generate_message(message_len,temp1,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     75\u001b[0m _,residual_predictions_0 \u001b[38;5;241m=\u001b[39m get_wmimages(text\u001b[38;5;241m=\u001b[39mtemp_tensor,image_i\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mrange\u001b[39m(image_i,image_i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m),encoder\u001b[38;5;241m=\u001b[39mencoder)\n\u001b[0;32m---> 76\u001b[0m _,residual_predictions_1 \u001b[38;5;241m=\u001b[39m \u001b[43mget_wmimages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemp1_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43mimage_i\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimage_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43mimage_i\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mencoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m residual_predictions_0_m \u001b[38;5;241m=\u001b[39m residual_predictions_0\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     79\u001b[0m residual_predictions_1_m \u001b[38;5;241m=\u001b[39m residual_predictions_1\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/data/shared/Huggingface/sharedcode/Stegastamp_CR/ipynb/functions.py:36\u001b[0m, in \u001b[0;36mget_wmimages\u001b[0;34m(ds, image_i, text, encoder, device, model_choice)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39minference_mode():\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m image_i:\n\u001b[0;32m---> 36\u001b[0m         image \u001b[38;5;241m=\u001b[39m \u001b[43mds\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m model_choice \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstega\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     38\u001b[0m             fingerprint_image,_,residual_image \u001b[38;5;241m=\u001b[39m encoder(fingerprints,image)\n",
      "File \u001b[0;32m~/.conda/envs/torch200/lib/python3.10/site-packages/torchvision/datasets/folder.py:231\u001b[0m, in \u001b[0;36mDatasetFolder.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    229\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader(path)\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 231\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m~/.conda/envs/torch200/lib/python3.10/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/.conda/envs/torch200/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/torch200/lib/python3.10/site-packages/torchvision/transforms/transforms.py:361\u001b[0m, in \u001b[0;36mResize.forward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m    354\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;124;03m        img (PIL Image or Tensor): Image to be scaled.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;124;03m        PIL Image or Tensor: Rescaled image.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 361\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mantialias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/torch200/lib/python3.10/site-packages/torchvision/transforms/functional.py:490\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    488\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnti-alias option is always applied for PIL Image input. Argument antialias is ignored.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    489\u001b[0m     pil_interpolation \u001b[38;5;241m=\u001b[39m pil_modes_mapping[interpolation]\n\u001b[0;32m--> 490\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_pil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpil_interpolation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F_t\u001b[38;5;241m.\u001b[39mresize(img, size\u001b[38;5;241m=\u001b[39moutput_size, interpolation\u001b[38;5;241m=\u001b[39minterpolation\u001b[38;5;241m.\u001b[39mvalue, antialias\u001b[38;5;241m=\u001b[39mantialias)\n",
      "File \u001b[0;32m~/.conda/envs/torch200/lib/python3.10/site-packages/torchvision/transforms/_functional_pil.py:250\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(size, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(size) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot inappropriate size arg: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 250\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/torch200/lib/python3.10/site-packages/PIL/Image.py:2200\u001b[0m, in \u001b[0;36mImage.resize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2192\u001b[0m             \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mreduce(\u001b[38;5;28mself\u001b[39m, factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[1;32m   2193\u001b[0m         box \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2194\u001b[0m             (box[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2195\u001b[0m             (box[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2196\u001b[0m             (box[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2197\u001b[0m             (box[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2198\u001b[0m         )\n\u001b[0;32m-> 2200\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbox\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/mnt/shared/Huggingface/sharedcode/Stegastamp_CR\")\n",
    "sys.path.append(\"/data/shared/Huggingface/sharedcode/Stegastamp_CR\")\n",
    "from utils.helpers import *\n",
    "from dataset import CustomImageFolder\n",
    "from torchvision import transforms\n",
    "from functools import partial\n",
    "import torch\n",
    "from functions import *\n",
    "from torchvision.datasets import ImageFolder\n",
    "from tqdm.auto import tqdm\n",
    "import csv\n",
    "\n",
    "set_seeds(2024)\n",
    "mi = \"mi\"\n",
    "device = torch.device(\"cuda:0\")\n",
    "for model_choice in [\"hidden\"]:\n",
    "    for data_choice in [\"CelebA\"]:\n",
    "        data_dir = {\"COCO\":\"/data/shared/coco2017/test2017\",\"CelebA\":\"/data/shared/deepfake/CelebA-HQ/val\"}\n",
    "        ckp_dir = f\"/data/shared/Huggingface/sharedcode/Stegastamp_Train/{mi}weights/{data_choice}/{model_choice}\"\n",
    "        transform_pipe = [\n",
    "            transforms.Resize((128,128)),\n",
    "            transforms.ToTensor(),\n",
    "        ]\n",
    "        normalize_ = transforms.Normalize(mean=[0.5,0.5,0.5],std=[0.5,0.5,0.5])\n",
    "        un_normalize_ = transforms.Normalize([-1,-1,-1],[2,2,2])\n",
    "        if model_choice == 'hidden':\n",
    "            transform_pipe.append(transforms.Normalize(mean=[0.5,0.5,0.5],std=[0.5,0.5,0.5]))\n",
    "        transform = transforms.Compose(transform_pipe)\n",
    "        if data_choice == \"CelebA\":\n",
    "            ds = ImageFolder(data_dir[data_choice],transform=transform)\n",
    "        else:\n",
    "            ds = CustomImageFolder(data_dir[data_choice],transform,num=1000)\n",
    "\n",
    "        # functions\n",
    "        get_wmimages = partial(get_wmimages,ds=ds,device=device,model_choice=model_choice)\n",
    "        get_images = partial(get_images,ds=ds,device=device)\n",
    "        extract_message = partial(extract_message,device=device,model_choice=model_choice)\n",
    "        csv_file = f\"/data/shared/Huggingface/sharedcode/Stegastamp_CR/xyattackresults/oriresults/{data_choice}_{model_choice}_{mi}.csv\"\n",
    "\n",
    "        # attack\n",
    "        message_len = 100\n",
    "        # ckp_list = sorted(os.listdir(ckp_dir))\n",
    "        ckp_list = [f\"{mi}OO\"]\n",
    "        ckp_list = [f\"{mi}emperical\"]\n",
    "        ckp_list = [f\"{mi}GN_0.1\"]\n",
    "        # ckp_list = [f\"{mi}affine_0.01\"]\n",
    "\n",
    "        \n",
    "        if f\"{mi}OO\" in ckp_list:\n",
    "            ckp_list.remove(f\"{mi}OO\")\n",
    "            ckp_list.insert(0,f\"{mi}OO\")\n",
    "        # ckp_list = [\"OO\",\"GN_0.1\",'GN_0.25','GN_0.5',\"affine_0.01\",\"affine_0.02\",\"affine_0.03\"]\n",
    "        for op in ckp_list:\n",
    "            if op == \"OO\":\n",
    "                ckp_path = os.path.join(ckp_dir,op,'epoch_499_state100.pth')\n",
    "            elif op == 'emperical':\n",
    "                ckp_path = os.path.join(ckp_dir,op,'epoch_499_state.pth')\n",
    "            else:\n",
    "                ckp_path = os.path.join(ckp_dir,op,'epoch_99_state.pth')\n",
    "\n",
    "            encoder,decoder = load_weights(ckp_path,model_choice,message_len)\n",
    "            encoder.eval(),decoder.eval()\n",
    "            targe_message = generate_message(message_len,batch_size=1)\n",
    "            for image_i in range(1000):\n",
    "                wm_images,residual_predictions = get_wmimages(text=targe_message,image_i=range(image_i,image_i+1),encoder=encoder)\n",
    "                residual_predictions_m = residual_predictions.mean(dim=0)\n",
    "                # similate \n",
    "                init_message = \"0\" * message_len\n",
    "                temp = init_message\n",
    "                for bit in tqdm(range(message_len)):\n",
    "                    temp1 = temp[:bit] + \"1\" + temp[bit+1:]\n",
    "                    temp_tensor = generate_message(message_len,temp,batch_size=1)\n",
    "                    temp1_tensor = generate_message(message_len,temp1,batch_size=1)\n",
    "                    _,residual_predictions_0 = get_wmimages(text=temp_tensor,image_i=range(image_i,image_i+1),encoder=encoder)\n",
    "                    _,residual_predictions_1 = get_wmimages(text=temp1_tensor,image_i=range(image_i,image_i+1),encoder=encoder)\n",
    "                    \n",
    "                    residual_predictions_0_m = residual_predictions_0.mean(dim=0)\n",
    "                    residual_predictions_1_m = residual_predictions_1.mean(dim=0)\n",
    "\n",
    "                    assert residual_predictions_0_m.size() == residual_predictions_1_m.size() == (3,128,128)\n",
    "\n",
    "                    dis0 = torch.norm(residual_predictions_m - residual_predictions_0_m).item()\n",
    "                    dis1 = torch.norm(residual_predictions_m - residual_predictions_1_m).item()\n",
    "                    if dis0 < dis1:\n",
    "                        temp = temp\n",
    "                    else:\n",
    "                        temp = temp1\n",
    "                \n",
    "                bit_acc = (message_len -  hamming_distance(temp,msg2str(targe_message))) / message_len\n",
    "                csv_dict = {\"model\":op,\"bit_acc\":bit_acc}\n",
    "                # with open(csv_file, mode='a', newline='') as file:\n",
    "                #     fieldnames = csv_dict.keys()\n",
    "                #     writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "                #     if file.tell() == 0:\n",
    "                #         writer.writeheader()\n",
    "                #     writer.writerow(csv_dict)\n",
    "                print(\"op:\",op)\n",
    "                print(\"temp:\",temp)\n",
    "                print(\"target:\",msg2str(targe_message))\n",
    "                print(\"hamming distance with temp with target_message:\",hamming_distance(temp,msg2str(targe_message)))  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def process_csv(file1, file2, output_file,score):\n",
    "    # 读取两个CSV文件\n",
    "    df1 = pd.read_csv(file1)\n",
    "    df2 = pd.read_csv(file2)\n",
    "    if score == 'forgedacc' or score == 'xyscore':\n",
    "        score = 'bit_acc'\n",
    "    # 去掉第二个文件中的`mi`前缀\n",
    "    df2['model'] = df2['model'].str.replace('mi', '', regex=False)\n",
    "    \n",
    "    # 提取 `bit_acc` 列并重命名\n",
    "    bit_acc1 = df1[['model', score]].rename(columns={score: 'wo_bit_acc'})\n",
    "    bit_acc2 = df2[['model', score]].rename(columns={score: 'w_bit_acc'})\n",
    "    \n",
    "    # 合并数据\n",
    "    merged_df = pd.merge(bit_acc1, bit_acc2, on='model', how='left')\n",
    "    \n",
    "    # 如果在第二个文件中没有出现的模型，其 w_bit_acc 设为 wo_bit_acc\n",
    "    merged_df['w_bit_acc'].fillna(merged_df['wo_bit_acc'], inplace=True)\n",
    "    \n",
    "    # 格式化结果\n",
    "    merged_df['wo_bit_acc'] = merged_df['wo_bit_acc'].apply(lambda x: f\"{x:.4f}\")\n",
    "    merged_df['w_bit_acc'] = merged_df['w_bit_acc'].apply(lambda x: f\"{x:.4f}\")\n",
    "    \n",
    "    # 保存到新的CSV文件\n",
    "    merged_df.to_csv(output_file, index=False)\n",
    "    \n",
    "\n",
    "score = \"xyscore\"\n",
    "for dataset in [\"COCO\",\"CelebA\"]:\n",
    "    for model in [\"stega\"]:\n",
    "        csv_file1 = f\"/data/shared/Huggingface/sharedcode/Stegastamp_CR/xyattackresults/{dataset}_{model}_.csv\"\n",
    "        csv_file2 = f\"/data/shared/Huggingface/sharedcode/Stegastamp_CR/xyattackresults/{dataset}_{model}_mi.csv\"\n",
    "        output_file = f'/data/shared/Huggingface/sharedcode/Stegastamp_CR/xyattackresults/comparsion_{dataset}_{model}_{score}.csv'\n",
    "        process_csv(csv_file1, csv_file2, output_file,score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch200",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
